package bot

import (
	"fmt"
	"strings"

	"github.com/LLZ-DinosaurEgg/douban-crawler/internal/db/model"
	sqlitepkg "github.com/LLZ-DinosaurEgg/douban-crawler/internal/db/sqlite"
)

// StyleLearner å›å¤é£æ ¼å­¦ä¹ å™¨
type StyleLearner struct {
	db *sqlitepkg.DB
}

// NewStyleLearner åˆ›å»ºé£æ ¼å­¦ä¹ å™¨
func NewStyleLearner(db *sqlitepkg.DB) *StyleLearner {
	return &StyleLearner{db: db}
}

// StyleAnalysis é£æ ¼åˆ†æç»“æœ
type StyleAnalysis struct {
	CommonPhrases    []string // å¸¸ç”¨çŸ­è¯­
	CommonWords      []string // å¸¸ç”¨è¯æ±‡
	AverageLength    int      // å¹³å‡é•¿åº¦
	CommonPatterns   []string // å¸¸è§æ¨¡å¼
	SampleComments   []string // æ ·æœ¬è¯„è®º
	SamplePosts      []string // æ ·æœ¬å¸–å­
}

// LearnGroupStyle å­¦ä¹ å°ç»„çš„å›å¤é£æ ¼
func (sl *StyleLearner) LearnGroupStyle(groupID string, maxPosts, maxComments int) (*StyleAnalysis, error) {
	// è·å–å†å²å¸–å­
	posts, err := sl.db.GetPostsByGroupID(groupID, maxPosts)
	if err != nil {
		return nil, fmt.Errorf("è·å–å¸–å­å¤±è´¥: %v", err)
	}

	// è·å–å†å²è¯„è®º
	comments, err := sl.db.GetCommentsByGroupID(groupID, maxComments)
	if err != nil {
		return nil, fmt.Errorf("è·å–è¯„è®ºå¤±è´¥: %v", err)
	}

	analysis := &StyleAnalysis{
		CommonPhrases:  []string{},
		CommonWords:    []string{},
		CommonPatterns: []string{},
		SampleComments: []string{},
		SamplePosts:    []string{},
	}

	// æ”¶é›†æ ·æœ¬
	totalLength := 0
	commentCount := 0
	wordFreq := make(map[string]int)
	phraseFreq := make(map[string]int)

	// åˆ†æè¯„è®º
	for _, comment := range comments {
		if comment.Content == "" {
			continue
		}
		
		content := strings.TrimSpace(comment.Content)
		if len(content) < 5 { // è·³è¿‡å¤ªçŸ­çš„è¯„è®º
			continue
		}

		analysis.SampleComments = append(analysis.SampleComments, content)
		totalLength += len(content)
		commentCount++

		// æå–å¸¸ç”¨è¯æ±‡ï¼ˆç®€å•åˆ†è¯ï¼‰
		words := strings.Fields(content)
		for _, word := range words {
			if len(word) > 1 {
				wordFreq[word]++
			}
		}

		// æå–å¸¸ç”¨çŸ­è¯­ï¼ˆ2-3ä¸ªè¯ï¼‰
		for i := 0; i < len(words)-1; i++ {
			if i+1 < len(words) {
				phrase := words[i] + " " + words[i+1]
				phraseFreq[phrase]++
			}
		}
	}

	// åˆ†æå¸–å­
	for _, post := range posts {
		if post.Content != "" {
			analysis.SamplePosts = append(analysis.SamplePosts, post.Title+"\n"+post.Content)
		}
	}

	// è®¡ç®—å¹³å‡é•¿åº¦
	if commentCount > 0 {
		analysis.AverageLength = totalLength / commentCount
	}

	// æå–æœ€å¸¸è§çš„è¯æ±‡ï¼ˆå‰20ä¸ªï¼‰
	analysis.CommonWords = getTopN(wordFreq, 20)

	// æå–æœ€å¸¸è§çš„çŸ­è¯­ï¼ˆå‰15ä¸ªï¼‰
	analysis.CommonPhrases = getTopN(phraseFreq, 15)

	// è¯†åˆ«å¸¸è§æ¨¡å¼
	analysis.CommonPatterns = sl.identifyPatterns(analysis.SampleComments)

	return analysis, nil
}

// identifyPatterns è¯†åˆ«å¸¸è§å›å¤æ¨¡å¼
func (sl *StyleLearner) identifyPatterns(comments []string) []string {
	patterns := []string{}

	// æ£€æŸ¥æ˜¯å¦ç»å¸¸ä½¿ç”¨é—®å·
	questionCount := 0
	for _, comment := range comments {
		if strings.Contains(comment, "ï¼Ÿ") || strings.Contains(comment, "?") {
			questionCount++
		}
	}
	if questionCount > len(comments)/3 {
		patterns = append(patterns, "ç»å¸¸ä½¿ç”¨ç–‘é—®å¥")
	}

	// æ£€æŸ¥æ˜¯å¦ç»å¸¸ä½¿ç”¨æ„Ÿå¹å·
	exclamationCount := 0
	for _, comment := range comments {
		if strings.Contains(comment, "ï¼") || strings.Contains(comment, "!") {
			exclamationCount++
		}
	}
	if exclamationCount > len(comments)/3 {
		patterns = append(patterns, "ç»å¸¸ä½¿ç”¨æ„Ÿå¹å¥")
	}

	// æ£€æŸ¥æ˜¯å¦ç»å¸¸ä½¿ç”¨è¡¨æƒ…ç¬¦å·
	emojiCount := 0
	emojis := []string{"ğŸ˜Š", "ğŸ˜‚", "ğŸ‘", "â¤ï¸", "ğŸ™", "ğŸ˜­", "ğŸ˜…", "ğŸ˜"}
	for _, comment := range comments {
		for _, emoji := range emojis {
			if strings.Contains(comment, emoji) {
				emojiCount++
				break
			}
		}
	}
	if emojiCount > len(comments)/4 {
		patterns = append(patterns, "ç»å¸¸ä½¿ç”¨è¡¨æƒ…ç¬¦å·")
	}

	// æ£€æŸ¥æ˜¯å¦ç»å¸¸ä½¿ç”¨"è°¢è°¢"ã€"æ„Ÿè°¢"ç­‰ç¤¼è²Œç”¨è¯­
	politeCount := 0
	politeWords := []string{"è°¢è°¢", "æ„Ÿè°¢", "è¯·é—®", "éº»çƒ¦", "ä¸å¥½æ„æ€"}
	for _, comment := range comments {
		for _, word := range politeWords {
			if strings.Contains(comment, word) {
				politeCount++
				break
			}
		}
	}
	if politeCount > len(comments)/3 {
		patterns = append(patterns, "ç»å¸¸ä½¿ç”¨ç¤¼è²Œç”¨è¯­")
	}

	return patterns
}

// getTopN è·å–é¢‘ç‡æœ€é«˜çš„Nä¸ªé¡¹
func getTopN(freqMap map[string]int, n int) []string {
	type pair struct {
		key   string
		value int
	}
	pairs := make([]pair, 0, len(freqMap))
	for k, v := range freqMap {
		pairs = append(pairs, pair{k, v})
	}

	// ç®€å•æ’åºï¼ˆå†’æ³¡æ’åºï¼Œå¯¹äºå°æ•°æ®é›†è¶³å¤Ÿï¼‰
	for i := 0; i < len(pairs)-1 && i < n; i++ {
		for j := i + 1; j < len(pairs); j++ {
			if pairs[j].value > pairs[i].value {
				pairs[i], pairs[j] = pairs[j], pairs[i]
			}
		}
	}

	result := make([]string, 0, n)
	for i := 0; i < len(pairs) && i < n; i++ {
		result = append(result, pairs[i].key)
	}
	return result
}

// BuildSystemPrompt æ„å»ºç³»ç»Ÿæç¤ºè¯
func (sl *StyleLearner) BuildSystemPrompt(groupName string, analysis *StyleAnalysis) string {
	prompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä¸ªè±†ç“£å°ç»„"%s"çš„è‡ªåŠ¨å›å¤æœºå™¨äººã€‚è¯·æ ¹æ®ä»¥ä¸‹é£æ ¼ç‰¹ç‚¹ç”Ÿæˆå›å¤ï¼š

é£æ ¼ç‰¹ç‚¹ï¼š
1. å¹³å‡å›å¤é•¿åº¦ï¼šçº¦%dä¸ªå­—ç¬¦
2. å¸¸ç”¨è¯æ±‡ï¼š%s
3. å¸¸ç”¨çŸ­è¯­ï¼š%s
4. å›å¤æ¨¡å¼ï¼š%s

å›å¤è¦æ±‚ï¼š
1. å›å¤è¦è‡ªç„¶ã€å‹å¥½ï¼Œç¬¦åˆè¯¥å°ç»„çš„äº¤æµé£æ ¼
2. ä½¿ç”¨è¯¥å°ç»„å¸¸ç”¨çš„è¯æ±‡å’Œè¡¨è¾¾æ–¹å¼
3. å›å¤é•¿åº¦è¦é€‚ä¸­ï¼Œä¸è¦è¿‡é•¿æˆ–è¿‡çŸ­
4. æ ¹æ®å¸–å­å†…å®¹ç»™å‡ºæœ‰æ„ä¹‰çš„å›å¤ï¼Œä¸è¦åªæ˜¯ç®€å•çš„"é¡¶"ã€"æ”¯æŒ"ç­‰
5. å¦‚æœå¸–å­æ˜¯æé—®ï¼Œè¦å°½é‡ç»™å‡ºæœ‰ç”¨çš„å»ºè®®æˆ–å›ç­”
6. ä¿æŒç¤¼è²Œå’Œå‹å–„çš„è¯­æ°”

è¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚ç”Ÿæˆå›å¤ã€‚`,
		groupName,
		analysis.AverageLength,
		strings.Join(analysis.CommonWords[:min(10, len(analysis.CommonWords))], "ã€"),
		strings.Join(analysis.CommonPhrases[:min(8, len(analysis.CommonPhrases))], "ã€"),
		strings.Join(analysis.CommonPatterns, "ã€"))

	return prompt
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
